{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnns_tf.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "VN-x3mUDBXRE",
        "OnVwGnZ9BdPt",
        "8IEpAbhWDClT"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VN-x3mUDBXRE",
        "colab_type": "text"
      },
      "source": [
        "## Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij7kBS4B-92B",
        "colab_type": "code",
        "outputId": "90368c74-6ff4-49ca-8e5b-88013a003bf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "vocab = {}\n",
        "word_encoding = 1\n",
        "def bag_of_words(text):\n",
        "    global word_encoding\n",
        "\n",
        "    words = text.lower().split(' ')\n",
        "    bag = {}\n",
        "\n",
        "    for word in words:\n",
        "        if word in vocab:\n",
        "            encoding = vocab[word]\n",
        "        else:\n",
        "            vocab[word] = word_encoding\n",
        "            encoding = word_encoding\n",
        "            word_encoding += 1\n",
        "\n",
        "        if encoding in bag:\n",
        "            bag[encoding] += 1\n",
        "        else:\n",
        "            bag[encoding] = 1\n",
        "        \n",
        "    return bag\n",
        "\n",
        "text = 'this is a test to see if this test will work is is test a a'\n",
        "bag = bag_of_words(text)\n",
        "print(bag)\n",
        "print(vocab)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 2, 2: 3, 3: 3, 4: 3, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1}\n",
            "{'this': 1, 'is': 2, 'a': 3, 'test': 4, 'to': 5, 'see': 6, 'if': 7, 'will': 8, 'work': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYtVKCf9AmbS",
        "colab_type": "code",
        "outputId": "10c709b6-ff25-4f93-c0ad-6502d960df35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# order of words is lost in the bag_of_words encoding technique\n",
        "positive_review = 'I thought the movie was going to be bad but it was actually amazing'\n",
        "negative_review = 'I thought the movie was going to be amazing but it was actually bad'\n",
        "\n",
        "pos_bag = bag_of_words(positive_review)\n",
        "neg_bag = bag_of_words(negative_review)\n",
        "\n",
        "print('Positive: ', pos_bag)\n",
        "print('Negative: ', neg_bag)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive:  {10: 1, 11: 1, 12: 1, 13: 1, 14: 2, 15: 1, 5: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1, 21: 1}\n",
            "Negative:  {10: 1, 11: 1, 12: 1, 13: 1, 14: 2, 15: 1, 5: 1, 16: 1, 21: 1, 18: 1, 19: 1, 20: 1, 17: 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnVwGnZ9BdPt",
        "colab_type": "text"
      },
      "source": [
        "## Integer Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeZ-v3C4BQE5",
        "colab_type": "code",
        "outputId": "e3f7cb8d-c2ff-4131-b651-c510ff89cac9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "vocab = {}\n",
        "word_encoding = 1\n",
        "def one_hot_encoding(text):\n",
        "    global word_encoding\n",
        "\n",
        "    words = text.lower().split(' ')\n",
        "    encoding = []\n",
        "\n",
        "    for word in words:\n",
        "        if word in vocab:\n",
        "            code = vocab[word]\n",
        "            encoding.append(code)\n",
        "        else:\n",
        "            vocab[word] = word_encoding\n",
        "            encoding.append(word_encoding)\n",
        "            word_encoding += 1\n",
        "    \n",
        "    return encoding\n",
        "\n",
        "text = 'this is a test to see if this test will work is is test a a'\n",
        "encoding = one_hot_encoding(text)\n",
        "print(encoding)\n",
        "print(vocab)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 1, 4, 8, 9, 2, 2, 4, 3, 3]\n",
            "{'this': 1, 'is': 2, 'a': 3, 'test': 4, 'to': 5, 'see': 6, 'if': 7, 'will': 8, 'work': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRF4xC4ZCQlS",
        "colab_type": "code",
        "outputId": "519ffca8-b82d-4cf0-86b7-0971df2f0e3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "positive_review = 'I thought the movie was going to be bad but it was actually amazing'\n",
        "negative_review = 'I thought the movie was going to be amazing but it was actually bad'\n",
        "\n",
        "pos_encode = one_hot_encoding(positive_review)\n",
        "neg_encode = one_hot_encoding(negative_review)\n",
        "\n",
        "print('Positive: ', pos_encode)\n",
        "print('Negative: ', neg_encode)\n",
        "\n",
        "#this technique is better cuz it keeps a track of the words in their order of occurence, but evidently not suitable as well..."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive:  [10, 11, 12, 13, 14, 15, 5, 16, 17, 18, 19, 14, 20, 21]\n",
            "Negative:  [10, 11, 12, 13, 14, 15, 5, 16, 21, 18, 19, 14, 20, 17]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IEpAbhWDClT",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Analysis using Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYlvWVGiCkso",
        "colab_type": "code",
        "outputId": "789a54a1-ca81-4541-9888-97e80f5ccf7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "import os\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "VOCAB_SIZE = 88584\n",
        "\n",
        "MAXLEN = 250\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = VOCAB_SIZE)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGfmqc0DFCKx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bef6a420-a7d1-454e-cdcc-5d6662acc5e2"
      },
      "source": [
        "X_train[1]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 194,\n",
              " 1153,\n",
              " 194,\n",
              " 8255,\n",
              " 78,\n",
              " 228,\n",
              " 5,\n",
              " 6,\n",
              " 1463,\n",
              " 4369,\n",
              " 5012,\n",
              " 134,\n",
              " 26,\n",
              " 4,\n",
              " 715,\n",
              " 8,\n",
              " 118,\n",
              " 1634,\n",
              " 14,\n",
              " 394,\n",
              " 20,\n",
              " 13,\n",
              " 119,\n",
              " 954,\n",
              " 189,\n",
              " 102,\n",
              " 5,\n",
              " 207,\n",
              " 110,\n",
              " 3103,\n",
              " 21,\n",
              " 14,\n",
              " 69,\n",
              " 188,\n",
              " 8,\n",
              " 30,\n",
              " 23,\n",
              " 7,\n",
              " 4,\n",
              " 249,\n",
              " 126,\n",
              " 93,\n",
              " 4,\n",
              " 114,\n",
              " 9,\n",
              " 2300,\n",
              " 1523,\n",
              " 5,\n",
              " 647,\n",
              " 4,\n",
              " 116,\n",
              " 9,\n",
              " 35,\n",
              " 8163,\n",
              " 4,\n",
              " 229,\n",
              " 9,\n",
              " 340,\n",
              " 1322,\n",
              " 4,\n",
              " 118,\n",
              " 9,\n",
              " 4,\n",
              " 130,\n",
              " 4901,\n",
              " 19,\n",
              " 4,\n",
              " 1002,\n",
              " 5,\n",
              " 89,\n",
              " 29,\n",
              " 952,\n",
              " 46,\n",
              " 37,\n",
              " 4,\n",
              " 455,\n",
              " 9,\n",
              " 45,\n",
              " 43,\n",
              " 38,\n",
              " 1543,\n",
              " 1905,\n",
              " 398,\n",
              " 4,\n",
              " 1649,\n",
              " 26,\n",
              " 6853,\n",
              " 5,\n",
              " 163,\n",
              " 11,\n",
              " 3215,\n",
              " 10156,\n",
              " 4,\n",
              " 1153,\n",
              " 9,\n",
              " 194,\n",
              " 775,\n",
              " 7,\n",
              " 8255,\n",
              " 11596,\n",
              " 349,\n",
              " 2637,\n",
              " 148,\n",
              " 605,\n",
              " 15358,\n",
              " 8003,\n",
              " 15,\n",
              " 123,\n",
              " 125,\n",
              " 68,\n",
              " 23141,\n",
              " 6853,\n",
              " 15,\n",
              " 349,\n",
              " 165,\n",
              " 4362,\n",
              " 98,\n",
              " 5,\n",
              " 4,\n",
              " 228,\n",
              " 9,\n",
              " 43,\n",
              " 36893,\n",
              " 1157,\n",
              " 15,\n",
              " 299,\n",
              " 120,\n",
              " 5,\n",
              " 120,\n",
              " 174,\n",
              " 11,\n",
              " 220,\n",
              " 175,\n",
              " 136,\n",
              " 50,\n",
              " 9,\n",
              " 4373,\n",
              " 228,\n",
              " 8255,\n",
              " 5,\n",
              " 25249,\n",
              " 656,\n",
              " 245,\n",
              " 2350,\n",
              " 5,\n",
              " 4,\n",
              " 9837,\n",
              " 131,\n",
              " 152,\n",
              " 491,\n",
              " 18,\n",
              " 46151,\n",
              " 32,\n",
              " 7464,\n",
              " 1212,\n",
              " 14,\n",
              " 9,\n",
              " 6,\n",
              " 371,\n",
              " 78,\n",
              " 22,\n",
              " 625,\n",
              " 64,\n",
              " 1382,\n",
              " 9,\n",
              " 8,\n",
              " 168,\n",
              " 145,\n",
              " 23,\n",
              " 4,\n",
              " 1690,\n",
              " 15,\n",
              " 16,\n",
              " 4,\n",
              " 1355,\n",
              " 5,\n",
              " 28,\n",
              " 6,\n",
              " 52,\n",
              " 154,\n",
              " 462,\n",
              " 33,\n",
              " 89,\n",
              " 78,\n",
              " 285,\n",
              " 16,\n",
              " 145,\n",
              " 95]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWQhrkelFFe_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = sequence.pad_sequences(X_train, MAXLEN)\n",
        "X_test = sequence.pad_sequences(X_test, MAXLEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6mde0huFVl_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential([\n",
        "                          keras.layers.Embedding(VOCAB_SIZE, 32),\n",
        "                          keras.layers.LSTM(32),\n",
        "                          keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQd-kmM4FrRW",
        "colab_type": "code",
        "outputId": "c2a5e9ff-77d3-4ec5-d158-58e4b902dba6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 32)          2834688   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 2,843,041\n",
            "Trainable params: 2,843,041\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyPuvnTyFsX9",
        "colab_type": "code",
        "outputId": "2a0faa10-13d5-44bb-8d45-ca101be343de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=15, validation_split=0.2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.4433 - acc: 0.7947 - val_loss: 0.3320 - val_acc: 0.8652\n",
            "Epoch 2/15\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 0.2487 - acc: 0.9049 - val_loss: 0.2762 - val_acc: 0.8860\n",
            "Epoch 3/15\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 0.1911 - acc: 0.9293 - val_loss: 0.2745 - val_acc: 0.8938\n",
            "Epoch 4/15\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 0.1565 - acc: 0.9459 - val_loss: 0.2888 - val_acc: 0.8850\n",
            "Epoch 5/15\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.1314 - acc: 0.9538 - val_loss: 0.2792 - val_acc: 0.8904\n",
            "Epoch 6/15\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 0.1125 - acc: 0.9621 - val_loss: 0.3767 - val_acc: 0.8864\n",
            "Epoch 7/15\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 0.0979 - acc: 0.9685 - val_loss: 0.3342 - val_acc: 0.8918\n",
            "Epoch 8/15\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 0.0865 - acc: 0.9718 - val_loss: 0.3241 - val_acc: 0.8890\n",
            "Epoch 9/15\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 0.0781 - acc: 0.9748 - val_loss: 0.4495 - val_acc: 0.8790\n",
            "Epoch 10/15\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.0694 - acc: 0.9776 - val_loss: 0.3459 - val_acc: 0.8802\n",
            "Epoch 11/15\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 0.0642 - acc: 0.9797 - val_loss: 0.3924 - val_acc: 0.8846\n",
            "Epoch 12/15\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 0.0555 - acc: 0.9827 - val_loss: 0.4194 - val_acc: 0.8836\n",
            "Epoch 13/15\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 0.0510 - acc: 0.9837 - val_loss: 0.4839 - val_acc: 0.8690\n",
            "Epoch 14/15\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.0454 - acc: 0.9856 - val_loss: 0.3812 - val_acc: 0.8834\n",
            "Epoch 15/15\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 0.0401 - acc: 0.9874 - val_loss: 0.4761 - val_acc: 0.8810\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnzkSSyAF_oj",
        "colab_type": "code",
        "outputId": "eb6a3004-b982-4f2e-fbcb-c2ce6eba5375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print('Test Accuracy: ', accuracy)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 5s 6ms/step - loss: 0.6661 - acc: 0.8327\n",
            "Test Accuracy:  0.8327199816703796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw6D3L-yGXwp",
        "colab_type": "code",
        "outputId": "429e5b62-5125-46f6-c0d9-c46cb61288d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "word_index = imdb.get_word_index()\n",
        "\n",
        "def encode_text(text):\n",
        "    tokens = keras.preprocessing.text.text_to_word_sequence(text)\n",
        "    tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
        "    return sequence.pad_sequences([tokens], MAXLEN)[0]\n",
        "\n",
        "text = 'that movie was just amazing, so amazing'\n",
        "encoded = encode_text(text)\n",
        "print(encoded)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 1s 0us/step\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0  12  17  13  40 477  35 477]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7fGrRrRHCDZ",
        "colab_type": "code",
        "outputId": "0c2fb584-bc17-4990-a9af-ec9045fe2043",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "reverse_word_index = {value: key for (key, value) in word_index.items()}\n",
        "\n",
        "def decode_integers(integers):\n",
        "    PAD = 0\n",
        "    text = ''\n",
        "    for num in integers:\n",
        "        if num != PAD:\n",
        "            text += reverse_word_index[num] + ' '\n",
        "    \n",
        "    return text[:-1]\n",
        "\n",
        "print(decode_integers(encoded))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "that movie was just amazing so amazing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR7awMMuHqoG",
        "colab_type": "code",
        "outputId": "24ba29f0-4c84-40a5-bd2f-4265d0f60963",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "def predict(text):\n",
        "    encoded_text = encode_text(text)\n",
        "    pred = np.zeros((1,250))\n",
        "    pred[0] = encoded_text\n",
        "    result = model.predict(pred)\n",
        "    print('Positive' if result[0][0]>0.5 else 'Negative', '({}%)'.format(round(result[0][0]*100)))\n",
        "\n",
        "positive_review = 'That movie was! really loved it and would great watch it again because it was amazingly great'\n",
        "negative_review = 'that movie really sucked. I hated it and wouldn\\'t watch it again. Was one of the worst things I\\'ve ever watched'\n",
        "\n",
        "predict(positive_review)\n",
        "predict(negative_review)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive (94.0%)\n",
            "Negative (27.0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4IAKrx9JT_I",
        "colab_type": "text"
      },
      "source": [
        "# RNN Play Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fgRPcKDJTKR",
        "colab_type": "code",
        "outputId": "9d51c8b3-a43f-4b52-f7d7-29c08138d2b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cOrCY5UIOZG",
        "colab_type": "code",
        "outputId": "43796ee9-ae17-49d0-a6c7-51e985362894",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "print('Length of characters: {}'.format(len(text)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of characters: 1115394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rhOxppdKeoQ",
        "colab_type": "code",
        "outputId": "e424dd90-b61c-4493-ab44-6196ed4dcb7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "print(text[:250])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBxlMGu0Khpd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = sorted(set(text))\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "def text_to_int(text):\n",
        "    return np.array([char2idx[c] for c in text])\n",
        "\n",
        "text_as_int = text_to_int(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSVHz48gLFN2",
        "colab_type": "code",
        "outputId": "0668c176-d092-4e93-bab0-920d7704465c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Text: ', text[:13])\n",
        "print('Encoded: ', text_to_int(text[:13]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text:  First Citizen\n",
            "Encoded:  [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8uAS9ByLWG6",
        "colab_type": "code",
        "outputId": "aeb014a2-11f3-4ece-8457-e636854cced7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def int_to_text(ints):\n",
        "    try:\n",
        "        ints = ints.numpy()\n",
        "    except:\n",
        "        pass\n",
        "    return ''.join(idx2char[ints])\n",
        "\n",
        "print(int_to_text(text_as_int[:13]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrD5JuR-LrMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating a training set to predict the next character\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhEW5bfNMTzT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TqZetMdMb9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_input_target(chunk): # hello\n",
        "    input_text = chunk[:-1] # hell\n",
        "    target_text = chunk[1:] # ello\n",
        "    return input_text, target_text # hell, ello\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O17TXkL-M6gZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "d615f8aa-36ec-4707-cee9-c5791d29c87a"
      },
      "source": [
        "for x,y in dataset.take(2):\n",
        "    print(\"EXAMPLE:\\n\")\n",
        "    print(\"INPUT\")\n",
        "    print(int_to_text(x), '\\n')\n",
        "    print(\"OUTPUT\")\n",
        "    print(int_to_text(y), '\\n')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EXAMPLE:\n",
            "\n",
            "INPUT\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You \n",
            "\n",
            "OUTPUT\n",
            "irst Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You  \n",
            "\n",
            "EXAMPLE:\n",
            "\n",
            "INPUT\n",
            "are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you  \n",
            "\n",
            "OUTPUT\n",
            "re all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you k \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK14hSAGNLNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "VOCAB_SIZE = len(vocab) # vocab is the number of unique chars\n",
        "EMBEDDING_DIM = 256\n",
        "RNN_UNITS = 1024\n",
        "\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjm1HdwpOClW",
        "colab_type": "code",
        "outputId": "dce121b4-69f2-4c12-c01f-1e3b62454ab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = keras.Sequential([\n",
        "                              keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
        "                              keras.layers.LSTM(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
        "                              keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
        "model.summary()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (64, None, 256)           16640     \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (64, None, 1024)          5246976   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (64, None, 65)            66625     \n",
            "=================================================================\n",
            "Total params: 5,330,241\n",
            "Trainable params: 5,330,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd6fC-8dO1V5",
        "colab_type": "code",
        "outputId": "4c52355d-113f-4852-87d5-61283abb92a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for input_example_batch, target_example_batch in data.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, '# (batch_size, sequence_length, vocab_size)')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwusJCLOPsN7",
        "colab_type": "code",
        "outputId": "aeaf3f79-730c-44e2-ba67-35153f11ba5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(len(example_batch_predictions))\n",
        "print(example_batch_predictions)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64\n",
            "tf.Tensor(\n",
            "[[[ 9.6880272e-04  3.0556913e-03  3.3980391e-03 ... -1.3966148e-04\n",
            "    1.9952897e-03 -7.1950373e-05]\n",
            "  [ 3.0743359e-03 -2.2219943e-03  2.6716525e-03 ...  3.7143948e-03\n",
            "    2.8870385e-03 -1.1140930e-03]\n",
            "  [ 4.4463533e-03  1.7829414e-03  1.5883931e-03 ...  1.5707205e-03\n",
            "    4.8416434e-05  1.0040414e-02]\n",
            "  ...\n",
            "  [ 6.9069518e-03 -4.7609517e-03 -4.0947595e-03 ...  2.2956398e-03\n",
            "    1.2813058e-02 -3.7204034e-03]\n",
            "  [ 8.0197789e-03 -7.8332692e-04 -4.4079744e-03 ...  5.5266498e-04\n",
            "    8.1237005e-03  7.2978735e-03]\n",
            "  [ 7.9727247e-03  4.6203355e-04 -7.5487336e-03 ...  2.3545930e-05\n",
            "    9.2085823e-03  4.1205185e-03]]\n",
            "\n",
            " [[ 1.7357501e-04 -2.2671786e-03  3.9059692e-03 ...  5.0990598e-04\n",
            "   -8.7830611e-04  8.7094854e-04]\n",
            "  [ 4.3279706e-03 -5.3087845e-03  9.0881018e-03 ...  1.1131704e-03\n",
            "   -3.9194003e-03 -1.9457079e-03]\n",
            "  [ 5.4120435e-03 -3.1920951e-03  5.0842343e-03 ... -2.3861080e-03\n",
            "   -1.5347456e-03 -2.1986235e-03]\n",
            "  ...\n",
            "  [-1.9716259e-04  9.0260990e-05 -6.1734514e-03 ... -7.8346375e-03\n",
            "    2.9718364e-03 -9.0083829e-04]\n",
            "  [ 1.1078798e-03  2.3536524e-04 -8.0688223e-03 ... -7.2147157e-03\n",
            "    5.8529256e-03 -1.5308032e-03]\n",
            "  [ 8.8007213e-04 -3.0428227e-03 -3.1392560e-03 ... -4.4027832e-03\n",
            "    4.3135821e-03 -6.4483628e-04]]\n",
            "\n",
            " [[-6.1430270e-05 -3.0556472e-03 -5.1725181e-03 ... -5.4558381e-03\n",
            "   -6.7341714e-03 -2.2822875e-03]\n",
            "  [-3.7409982e-03  3.4436519e-04 -5.2929851e-03 ... -9.5829032e-03\n",
            "   -5.9815054e-04 -2.9961369e-04]\n",
            "  [-1.8761331e-03  1.5081211e-03 -6.5399539e-03 ... -9.3527175e-03\n",
            "    3.0123680e-03 -1.1774192e-03]\n",
            "  ...\n",
            "  [ 5.9043225e-03  8.2684522e-03  1.3381140e-03 ... -3.9041261e-03\n",
            "    1.0960353e-02 -2.3926138e-03]\n",
            "  [ 7.2681671e-03  4.1585602e-03 -1.7864443e-03 ... -2.6566817e-03\n",
            "    2.0709590e-03 -5.2364999e-03]\n",
            "  [ 3.4549893e-03  4.0423975e-04 -1.4800129e-03 ... -2.5791763e-03\n",
            "    9.9171028e-03 -7.2819665e-03]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 1.7357501e-04 -2.2671786e-03  3.9059692e-03 ...  5.0990598e-04\n",
            "   -8.7830611e-04  8.7094854e-04]\n",
            "  [ 2.1052242e-03  1.3340355e-03  3.3009595e-03 ... -3.4384525e-03\n",
            "   -3.3432792e-03  1.0003045e-02]\n",
            "  [ 1.9143615e-03  4.8956680e-03  5.5225706e-03 ... -3.4264033e-03\n",
            "   -4.3598586e-04  6.3892044e-03]\n",
            "  ...\n",
            "  [ 5.0350358e-03  2.0470130e-03 -4.3357583e-03 ... -5.7730656e-03\n",
            "    4.8171300e-03  4.0633464e-04]\n",
            "  [ 7.6733204e-03 -1.2354692e-03 -2.3637132e-03 ... -6.4336741e-03\n",
            "   -6.0108112e-04  3.2377478e-03]\n",
            "  [ 5.8043851e-03 -3.9089140e-03 -1.1850863e-03 ... -4.5855818e-03\n",
            "    7.2324472e-03  4.0496010e-03]]\n",
            "\n",
            " [[ 3.8505970e-03  6.9237784e-03  6.9013890e-03 ... -3.3144939e-03\n",
            "   -1.8661318e-05 -3.7176558e-03]\n",
            "  [ 3.3690589e-03  8.1552071e-03  8.8311434e-03 ... -2.8413942e-03\n",
            "    1.7666824e-03 -3.7510612e-03]\n",
            "  [ 2.1774534e-03  3.1810210e-03  1.2495201e-03 ... -7.3939050e-03\n",
            "   -5.7899477e-03 -5.5229873e-03]\n",
            "  ...\n",
            "  [ 6.3339090e-03 -7.4721859e-03 -1.4417574e-03 ... -5.6972271e-03\n",
            "    3.0651828e-04 -1.8623295e-03]\n",
            "  [ 5.5753975e-03 -9.5447060e-03 -1.9588536e-03 ... -5.0837696e-03\n",
            "   -2.5689262e-03 -7.8318547e-04]\n",
            "  [ 5.3351503e-03 -6.3650943e-03  1.6797683e-03 ... -3.8957675e-03\n",
            "   -6.8059424e-04 -1.7899158e-04]]\n",
            "\n",
            " [[-2.7116719e-03 -2.3144067e-03  1.7874751e-03 ...  1.3475632e-04\n",
            "    7.6343566e-03 -1.9482041e-03]\n",
            "  [-6.1815383e-04 -3.4965922e-03  4.5569381e-03 ...  2.4712645e-04\n",
            "    9.2875669e-03 -1.2824771e-03]\n",
            "  [ 2.3375498e-03 -8.2288356e-04  1.5720832e-03 ... -1.9078343e-03\n",
            "    9.9899042e-03 -1.5856012e-03]\n",
            "  ...\n",
            "  [ 3.0855630e-03  4.4503044e-03 -1.9144474e-03 ... -8.2263257e-04\n",
            "    6.6517051e-03 -3.8904366e-03]\n",
            "  [ 2.4414153e-03  6.4896140e-04  4.5593444e-04 ... -1.5810184e-04\n",
            "    4.8743030e-03 -2.2762644e-03]\n",
            "  [ 1.5447168e-03 -3.0518968e-03 -7.0589730e-03 ... -7.2570560e-03\n",
            "   -2.5096247e-03 -4.4837478e-03]]], shape=(64, 100, 65), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiKsL5guQAtX",
        "colab_type": "code",
        "outputId": "517971ee-6f3d-4187-abc6-30edec008bea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "pred = example_batch_predictions[0]\n",
        "print(len(pred))\n",
        "print(pred)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n",
            "tf.Tensor(\n",
            "[[ 9.6880272e-04  3.0556913e-03  3.3980391e-03 ... -1.3966148e-04\n",
            "   1.9952897e-03 -7.1950373e-05]\n",
            " [ 3.0743359e-03 -2.2219943e-03  2.6716525e-03 ...  3.7143948e-03\n",
            "   2.8870385e-03 -1.1140930e-03]\n",
            " [ 4.4463533e-03  1.7829414e-03  1.5883931e-03 ...  1.5707205e-03\n",
            "   4.8416434e-05  1.0040414e-02]\n",
            " ...\n",
            " [ 6.9069518e-03 -4.7609517e-03 -4.0947595e-03 ...  2.2956398e-03\n",
            "   1.2813058e-02 -3.7204034e-03]\n",
            " [ 8.0197789e-03 -7.8332692e-04 -4.4079744e-03 ...  5.5266498e-04\n",
            "   8.1237005e-03  7.2978735e-03]\n",
            " [ 7.9727247e-03  4.6203355e-04 -7.5487336e-03 ...  2.3545930e-05\n",
            "   9.2085823e-03  4.1205185e-03]], shape=(100, 65), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_suPiqSDQKGk",
        "colab_type": "code",
        "outputId": "ff8914c3-a525-4119-94bb-03e4596afa68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "time_pred = pred[0]\n",
        "print(len(time_pred))\n",
        "print(time_pred)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65\n",
            "tf.Tensor(\n",
            "[ 9.6880272e-04  3.0556913e-03  3.3980391e-03 -1.0073746e-03\n",
            " -6.0003502e-03 -3.6005834e-03 -8.4221183e-04  8.8817289e-04\n",
            "  2.4361722e-03  7.0229650e-04  4.0602819e-03 -1.2154115e-03\n",
            " -2.9926936e-03  3.9789854e-03  2.7092511e-04 -3.1422945e-03\n",
            " -7.5713354e-03 -8.0915401e-04  1.1393141e-03  4.6523996e-03\n",
            "  1.8723740e-04  2.5818120e-03  9.5314570e-03 -7.4303062e-03\n",
            "  3.3640021e-03 -3.0034173e-03 -6.7128870e-04  5.5252006e-03\n",
            " -6.6528394e-04  1.6011856e-04 -3.4095726e-03 -1.2598583e-04\n",
            " -1.5860993e-03  8.5732486e-04 -9.1161230e-04 -5.4355443e-04\n",
            " -2.0609151e-03  1.7321610e-03 -3.1430656e-03 -3.3081633e-03\n",
            "  1.9767212e-03 -6.1710542e-03 -3.6768154e-03 -1.0245168e-03\n",
            "  2.9124448e-03  3.2009366e-03 -2.8033825e-03 -3.0788681e-03\n",
            " -3.4109987e-03  4.6167220e-04 -2.8742822e-03 -2.7631156e-03\n",
            " -1.7249414e-03  1.6480217e-03 -2.1683809e-04  3.3935625e-03\n",
            "  4.1514621e-03  5.6266016e-04 -8.6298753e-03 -8.6520950e-04\n",
            " -2.0970432e-03  1.8685800e-03 -1.3966148e-04  1.9952897e-03\n",
            " -7.1950373e-05], shape=(65,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ithy6uXqQat0",
        "colab_type": "code",
        "outputId": "c0b5565a-e832-4db2-93d2-1fa660b3a26c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "sampled_indices = tf.random.categorical(pred, num_samples=1)\n",
        "\n",
        "sampled_indices = np.reshape(sampled_indices, (1,-1))[0]\n",
        "predicted_chars = int_to_text(sampled_indices)\n",
        "\n",
        "print(predicted_chars)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "RdgDp.:kO!WlMd&LzsbsACKKwk?'I.x:JJUuSZZWeG\n",
            "\n",
            "?m3krnPi:PS;g:wIgJW,nibxTS'\n",
            "fmmZOX'W.hMuI KKlrZhHJK-cka\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8euGjK3Q08t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we have a very weird output shape and hence need to define a special loss function for it as preloaded ones wont work\n",
        "\n",
        "def loss(labels, logits):\n",
        "    return keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIFo-HlnROYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdufKDZRRZIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model checkpointing will be done to resume training from a given checkpoint\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'chk_{epoch}.h5')\n",
        "\n",
        "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath = checkpoint_prefix,\n",
        "    save_weights_only = True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm0r91MvqcrV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1a1a8136-24e6-43d7-e705-e40fb40e035a"
      },
      "source": [
        "history = model.fit(data, epochs=50, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 1.7848 - accuracy: 0.4753\n",
            "Epoch 2/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 1.5964 - accuracy: 0.5259\n",
            "Epoch 3/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 1.4814 - accuracy: 0.5558\n",
            "Epoch 4/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 1.4088 - accuracy: 0.5747\n",
            "Epoch 5/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 1.3566 - accuracy: 0.5880\n",
            "Epoch 6/50\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 1.3139 - accuracy: 0.5994\n",
            "Epoch 7/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 1.2753 - accuracy: 0.6098\n",
            "Epoch 8/50\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 1.2401 - accuracy: 0.6190\n",
            "Epoch 9/50\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 1.2058 - accuracy: 0.6289\n",
            "Epoch 10/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 1.1715 - accuracy: 0.6395\n",
            "Epoch 11/50\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 1.1342 - accuracy: 0.6505\n",
            "Epoch 12/50\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 1.0978 - accuracy: 0.6623\n",
            "Epoch 13/50\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 1.0605 - accuracy: 0.6741\n",
            "Epoch 14/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 1.0202 - accuracy: 0.6872\n",
            "Epoch 15/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.9813 - accuracy: 0.7011\n",
            "Epoch 16/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.9423 - accuracy: 0.7148\n",
            "Epoch 17/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.9034 - accuracy: 0.7288\n",
            "Epoch 18/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.8681 - accuracy: 0.7420\n",
            "Epoch 19/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.8334 - accuracy: 0.7546\n",
            "Epoch 20/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.8005 - accuracy: 0.7668\n",
            "Epoch 21/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.7680 - accuracy: 0.7786\n",
            "Epoch 22/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.7414 - accuracy: 0.7884\n",
            "Epoch 23/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.7161 - accuracy: 0.7985\n",
            "Epoch 24/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.6916 - accuracy: 0.8071\n",
            "Epoch 25/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.6695 - accuracy: 0.8155\n",
            "Epoch 26/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.6497 - accuracy: 0.8227\n",
            "Epoch 27/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.6335 - accuracy: 0.8286\n",
            "Epoch 28/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.6160 - accuracy: 0.8354\n",
            "Epoch 29/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.6009 - accuracy: 0.8408\n",
            "Epoch 30/50\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.5872 - accuracy: 0.8460\n",
            "Epoch 31/50\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.5746 - accuracy: 0.8497\n",
            "Epoch 32/50\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.5636 - accuracy: 0.8550\n",
            "Epoch 33/50\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.5534 - accuracy: 0.8583\n",
            "Epoch 34/50\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.5431 - accuracy: 0.8624\n",
            "Epoch 35/50\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.5338 - accuracy: 0.8652\n",
            "Epoch 36/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.5254 - accuracy: 0.8683\n",
            "Epoch 37/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.5184 - accuracy: 0.8710\n",
            "Epoch 38/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.5115 - accuracy: 0.8734\n",
            "Epoch 39/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.5035 - accuracy: 0.8764\n",
            "Epoch 40/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.4981 - accuracy: 0.8784\n",
            "Epoch 41/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.4932 - accuracy: 0.8794\n",
            "Epoch 42/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.4863 - accuracy: 0.8824\n",
            "Epoch 43/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.4800 - accuracy: 0.8848\n",
            "Epoch 44/50\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.4775 - accuracy: 0.8860\n",
            "Epoch 45/50\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.4740 - accuracy: 0.8866\n",
            "Epoch 46/50\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.4696 - accuracy: 0.8882\n",
            "Epoch 47/50\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.4658 - accuracy: 0.8891\n",
            "Epoch 48/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.4634 - accuracy: 0.8902\n",
            "Epoch 49/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.4592 - accuracy: 0.8911\n",
            "Epoch 50/50\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.4574 - accuracy: 0.8926\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n6tKUfTsmaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipQXHA8kwtJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhxrIQFRtTq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# checkpoint_num = 10\n",
        "# model.load_weights(tf.train.load_checkpoint(\"./training_checkpoints/chk_\" + str(checkpoint_num) + '.h5'))\n",
        "# model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yl-MtR_QtpQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "    num_generate = 800\n",
        "\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    text_generated = []\n",
        "\n",
        "    temperature = 1.0 # this is a randomizer magnitude, low_temp is more preidictable, high_temp is more surprising\n",
        "\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "\n",
        "        predictions = tf.squeeze(predictions, 0) # removing batch dimension\n",
        "\n",
        "        predictions = predictions/temperature # using a categorical distribution to predict the character returned by the model\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return (start_string + ''.join(text_generated))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb_J0vwnxdSx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "ce65b3b3-e43e-48bc-de93-ec405c6ab517"
      },
      "source": [
        "inp = input('Start typing a string: ')\n",
        "print(generate_text(model, inp))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start typing a string: Hello\n",
            "Hellod.\n",
            "\n",
            "PROSPERO:\n",
            "No, boy! good repose, but though my man has my vole to bed.\n",
            "What makes you frown: to't your evil displeasure's\n",
            "ow;\n",
            "I would or great angeles. What ballad is this?\n",
            "The man I find I have poison with this bond.\n",
            "\n",
            "WARWICK:\n",
            "Onfeitner,\n",
            "Thou canst not speak, and every office lunity\n",
            "and all the rest fear the great sorrow this way\n",
            "The head of merit, will you talk of servant;\n",
            "And, for the least shunning a foul grave is likely.\n",
            "\n",
            "BAPTISTA:\n",
            "Why, tell me, you're well believe your babe, but march am bound\n",
            "to entreat my trick,\n",
            "And branches may be gone about a ciper: I\n",
            "make a good heart that move, please my study,\n",
            "And twelve a baby's carpendan took.\n",
            "\n",
            "KATHARINA:\n",
            "Was ever man so still and women come.\n",
            "Hark! Hast thou from Pristo and the King of Naples,\n",
            "Suito thy drum.\n",
            "\n",
            "LUCENTIO:\n",
            "What marriage I wi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBZM7LD60lBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}